{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc3e4399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Feature Engineering...\n",
      "Dividiendo datos: Train <= 2016, Val <= 2017, Test > 2017\n",
      "Train: 1805 muestras (2009-2016)\n",
      "Validation: 228 muestras (2017-2017)\n",
      "Test: 456 muestras (2018-2019)\n",
      "Preparando datos para entrenamiento...\n",
      "Aprendiendo estadísticas de empresas del set de entrenamiento...\n",
      "Entrenando con 24 features.\n",
      "Entrenamiento completado.\n",
      "Evaluando en el conjunto de prueba...\n",
      "\n",
      "=== MÉTRICAS GENERALES (TEST SET) ===\n",
      "WAPE: 5.51%\n",
      "MAE: 5173.96 MWh\n",
      "RMSE: 9631.38 MWh\n",
      "R²: 0.9921\n",
      "\n",
      "=== MÉTRICAS POR EMPRESA (TEST SET) ===\n",
      "            mae_empresa  mape_empresa  r2_empresa  mean_consumption\n",
      "IdEmpresa                                                          \n",
      "11          1153.497634      2.080807    0.025145      55445.964134\n",
      "30          2073.557282      2.282737   -0.021840      90753.610635\n",
      "142         1109.783223      2.349026   -0.006403      48240.730685\n",
      "191         1409.922541      2.465282    0.314462      57414.182110\n",
      "174         9019.203312      2.493576   -1.282100     360881.945395\n",
      "178         1051.929182      3.305715    0.114531      31450.259729\n",
      "189         2153.660362      3.836125    0.555942      53739.298653\n",
      "26         17851.718074      4.218002   -0.132542     413807.187897\n",
      "35          2075.376564      4.477221   -0.088336      47164.259705\n",
      "20           353.033040      4.715063   -6.786809       7456.311208\n",
      "136         3047.622127      4.898125    0.601598      61683.821307\n",
      "130         1800.608473      5.371069   -0.113998      32942.621527\n",
      "54          5065.847689      5.478182   -0.154498      90429.433883\n",
      "72          2322.446271      5.995107   -0.248209      38863.512122\n",
      "193         3289.668098      8.321838    0.526360      32904.314683\n",
      "17           710.603002      8.404805   -0.178470       8917.237381\n",
      "134        10556.090559      8.733099   -3.801241     120926.921066\n",
      "192         6455.132466     11.708376   -0.707795      55807.241233\n",
      "87         26805.567930     14.954707   -7.032005     176712.353738\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def calculate_wape(y_true, y_pred):\n",
    "    \"\"\"Calcula el Weighted Average Percentage Error (WAPE).\"\"\"\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "\n",
    "class EnergyConsumptionPredictorXGB:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.company_encoder = LabelEncoder()\n",
    "        self.feature_importance = None\n",
    "        self.company_stats_map = None # Almacenará las estadísticas del training set\n",
    "\n",
    "    # --- LAS FUNCIONES DE FEATURE ENGINEERING (lag, rolling, seasonal) PERMANECEN IGUAL ---\n",
    "    # (Se omiten por brevedad, son las mismas que proporcionaste y están bien diseñadas)\n",
    "    def create_lag_features(self, df, target_col, lags):\n",
    "        df_lag = df.copy()\n",
    "        for lag in lags:\n",
    "            df_lag[f'{target_col}_lag_{lag}'] = df_lag.groupby('IdEmpresa')[target_col].shift(lag)\n",
    "        return df_lag\n",
    "\n",
    "    def create_rolling_features(self, df, target_col, windows):\n",
    "        df_roll = df.copy()\n",
    "        for window in windows:\n",
    "            df_roll[f'{target_col}_rolling_mean_{window}'] = df_roll.groupby('IdEmpresa')[target_col].transform(lambda x: x.shift(1).rolling(window=window, min_periods=1).mean())\n",
    "            df_roll[f'{target_col}_rolling_std_{window}'] = df_roll.groupby('IdEmpresa')[target_col].transform(lambda x: x.shift(1).rolling(window=window, min_periods=1).std())\n",
    "        return df_roll\n",
    "        \n",
    "    def create_seasonal_features(self, df):\n",
    "        df_seasonal = df.copy()\n",
    "        df_seasonal['mes_sin'] = np.sin(2 * np.pi * df_seasonal['IdMes'] / 12)\n",
    "        df_seasonal['mes_cos'] = np.cos(2 * np.pi * df_seasonal['IdMes'] / 12)\n",
    "        return df_seasonal\n",
    "\n",
    "    # --- CORRECCIÓN CRÍTICA DE FUGA DE DATOS ---\n",
    "    def fit_company_features(self, df_train):\n",
    "        \"\"\"\n",
    "        Aprende las estadísticas de las empresas SOLO del conjunto de entrenamiento.\n",
    "        \"\"\"\n",
    "        print(\"Aprendiendo estadísticas de empresas del set de entrenamiento...\")\n",
    "        company_stats = df_train.groupby('IdEmpresa')['Energía Facturada (MWh)'].agg(\n",
    "            mean='mean', std='std', max='max'\n",
    "        ).reset_index()\n",
    "        company_stats.columns = ['IdEmpresa', 'empresa_mean_historica', 'empresa_std_historica', 'empresa_max_historica']\n",
    "        self.company_stats_map = company_stats.set_index('IdEmpresa')\n",
    "\n",
    "    def transform_company_features(self, df):\n",
    "        \"\"\"\n",
    "        Aplica las estadísticas aprendidas a cualquier conjunto de datos (train, val, test).\n",
    "        \"\"\"\n",
    "        if self.company_stats_map is None:\n",
    "            raise RuntimeError(\"Debes llamar a 'fit_company_features' primero.\")\n",
    "        \n",
    "        df_company = df.merge(self.company_stats_map, on='IdEmpresa', how='left')\n",
    "        \n",
    "        # Llenar NaNs para empresas que no estaban en el training set (si aplica)\n",
    "        for col in ['empresa_mean_historica', 'empresa_std_historica', 'empresa_max_historica']:\n",
    "             df_company[col].fillna(self.company_stats_map[col].mean(), inplace=True)\n",
    "\n",
    "        df_company['IdEmpresa_encoded'] = self.company_encoder.fit_transform(df_company['IdEmpresa'])\n",
    "        return df_company\n",
    "\n",
    "    def feature_engineering(self, df):\n",
    "        print(\"Iniciando Feature Engineering...\")\n",
    "        df = df.sort_values(['IdEmpresa', 'Año', 'IdMes']).reset_index(drop=True)\n",
    "\n",
    "        lag_periods = [1, 2, 3, 6, 12]\n",
    "        df = self.create_lag_features(df, 'Energía Facturada (MWh)', lag_periods)\n",
    "\n",
    "        rolling_windows = [3, 6, 12]\n",
    "        df = self.create_rolling_features(df, 'Energía Facturada (MWh)', rolling_windows)\n",
    "        \n",
    "        df = self.create_seasonal_features(df)\n",
    "        df['tendencia_temporal'] = (df['Año'] - df['Año'].min()) * 12 + df['IdMes']\n",
    "        \n",
    "        # Las features de empresa se aplican después de la división de datos\n",
    "        return df\n",
    "\n",
    "    def temporal_split(self, df, train_end_year, val_end_year):\n",
    "        \"\"\"División temporal estricta en train, validation y test.\"\"\"\n",
    "        print(f\"Dividiendo datos: Train <= {train_end_year}, Val <= {val_end_year}, Test > {val_end_year}\")\n",
    "        \n",
    "        train_df = df[df['Año'] <= train_end_year].copy()\n",
    "        val_df = df[(df['Año'] > train_end_year) & (df['Año'] <= val_end_year)].copy()\n",
    "        test_df = df[df['Año'] > val_end_year].copy()\n",
    "\n",
    "        print(f\"Train: {len(train_df)} muestras ({train_df['Año'].min()}-{train_df['Año'].max()})\")\n",
    "        print(f\"Validation: {len(val_df)} muestras ({val_df['Año'].min()}-{val_df['Año'].max()})\")\n",
    "        print(f\"Test: {len(test_df)} muestras ({test_df['Año'].min()}-{test_df['Año'].max()})\")\n",
    "        \n",
    "        return train_df, val_df, test_df\n",
    "\n",
    "    def train(self, df_train, df_val):\n",
    "        \"\"\"Entrenar modelo XGBoost con validación para early stopping.\"\"\"\n",
    "        print(\"Preparando datos para entrenamiento...\")\n",
    "        \n",
    "        # 1. Aprender y transformar features de empresa EN EL SET DE ENTRENAMIENTO\n",
    "        self.fit_company_features(df_train)\n",
    "        train_processed = self.transform_company_features(df_train)\n",
    "        \n",
    "        # 2. Aplicar las mismas transformaciones al set de validación\n",
    "        val_processed = self.transform_company_features(df_val)\n",
    "        \n",
    "        # Eliminar filas con NaNs generados por lags/rolling\n",
    "        train_processed.dropna(subset=['Energía Facturada (MWh)'], inplace=True)\n",
    "        val_processed.dropna(subset=['Energía Facturada (MWh)'], inplace=True)\n",
    "        \n",
    "        y_train = train_processed['Energía Facturada (MWh)']\n",
    "        y_val = val_processed['Energía Facturada (MWh)']\n",
    "\n",
    "        exclude_cols = ['IdEmpresa', 'Energía Facturada (MWh)', 'Año']\n",
    "        feature_cols = [col for col in train_processed.columns if col not in exclude_cols]\n",
    "        \n",
    "        X_train = train_processed[feature_cols].fillna(0) # Rellenar cualquier NaN restante\n",
    "        X_val = val_processed[feature_cols].fillna(0)\n",
    "\n",
    "        print(f\"Entrenando con {len(X_train.columns)} features.\")\n",
    "        \n",
    "        params = {\n",
    "            'n_estimators': 1000, # Aumentado, early stopping encontrará el mejor\n",
    "            'learning_rate': 0.03,\n",
    "            'max_depth': 7,\n",
    "            'min_child_weight': 1,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'eval_metric': 'rmse',\n",
    "            'early_stopping_rounds': 50, # Para early stopping\n",
    "        }\n",
    "        self.model = xgb.XGBRegressor(**params)\n",
    "\n",
    "        # CORRECTO: Usar el set de validación para early stopping\n",
    "        eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "        self.model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=eval_set,\n",
    "          #  eval_metric='rmse',\n",
    "           # early_stopping_rounds=50, # Detener si el RMSE de validación no mejora en 50 rondas\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        self.feature_importance = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(\"Entrenamiento completado.\")\n",
    "    \n",
    "    def evaluate(self, df_test):\n",
    "        \"\"\"Evaluar modelo en el conjunto de prueba.\"\"\"\n",
    "        print(\"Evaluando en el conjunto de prueba...\")\n",
    "        \n",
    "        # Aplicar las transformaciones aprendidas\n",
    "        test_processed = self.transform_company_features(df_test)\n",
    "        \n",
    "        y_test = test_processed['Energía Facturada (MWh)']\n",
    "        exclude_cols = ['IdEmpresa', 'Energía Facturada (MWh)', 'Año']\n",
    "        feature_cols = [col for col in test_processed.columns if col not in exclude_cols]\n",
    "        X_test = test_processed[feature_cols].fillna(0)\n",
    "        \n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Métricas Globales\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        wape = calculate_wape(y_test, y_pred)\n",
    "        \n",
    "        print(\"\\n=== MÉTRICAS GENERALES (TEST SET) ===\")\n",
    "        print(f\"WAPE: {wape:.2f}%\")\n",
    "        print(f\"MAE: {mae:.2f} MWh\")\n",
    "        print(f\"RMSE: {rmse:.2f} MWh\")\n",
    "        print(f\"R²: {r2:.4f}\")\n",
    "        \n",
    "        # Métricas por Empresa\n",
    "        results_df = pd.DataFrame({\n",
    "            'IdEmpresa': test_processed['IdEmpresa'],\n",
    "            'y_true': y_test,\n",
    "            'y_pred': y_pred\n",
    "        })\n",
    "\n",
    "        company_metrics_list = []\n",
    "        for empresa_id in results_df['IdEmpresa'].unique():\n",
    "            subset = results_df[results_df['IdEmpresa'] == empresa_id]\n",
    "            mae_emp = mean_absolute_error(subset['y_true'], subset['y_pred'])\n",
    "            mape_emp = np.mean(np.abs((subset['y_true'] - subset['y_pred']) / subset['y_true'])) * 100\n",
    "            r2_emp = r2_score(subset['y_true'], subset['y_pred'])\n",
    "            company_metrics_list.append({\n",
    "                'IdEmpresa': empresa_id,\n",
    "                'mae_empresa': mae_emp,\n",
    "                'mape_empresa': mape_emp,\n",
    "                'r2_empresa': r2_emp,\n",
    "                'mean_consumption': subset['y_true'].mean()\n",
    "            })\n",
    "        \n",
    "        company_metrics = pd.DataFrame(company_metrics_list).set_index('IdEmpresa')\n",
    "        print(\"\\n=== MÉTRICAS POR EMPRESA (TEST SET) ===\")\n",
    "        print(company_metrics.sort_values('mape_empresa'))\n",
    "\n",
    "# --- Pipeline de Ejecución ---\n",
    "def run_xgb_pipeline(df):\n",
    "    predictor = EnergyConsumptionPredictorXGB()\n",
    "    \n",
    "    # 1. Feature Engineering general (sin leakage)\n",
    "    df_featured = predictor.feature_engineering(df)\n",
    "    \n",
    "    # 2. División temporal estricta\n",
    "    train_df, val_df, test_df = predictor.temporal_split(df_featured, train_end_year=2016, val_end_year=2017)\n",
    "    \n",
    "    # 3. Entrenamiento (aprende de train, valida con val)\n",
    "    predictor.train(train_df, val_df)\n",
    "    \n",
    "    # 4. Evaluación final (en datos nunca vistos)\n",
    "    predictor.evaluate(test_df)\n",
    "    \n",
    "    return predictor\n",
    "\n",
    "# Uso:\n",
    "df = pd.read_csv('df_dataset_unidos5.csv')\n",
    "xgb_predictor = run_xgb_pipeline(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
